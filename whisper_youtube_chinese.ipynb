{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Youtube Videos Transcription with OpenAI's Whisper**\n",
        "\n",
        "[![blog post shield](https://img.shields.io/static/v1?label=&message=Blog%20post&color=blue&style=for-the-badge&logo=openai&link=https://openai.com/blog/whisper)](https://openai.com/blog/whisper)\n",
        "[![notebook shield](https://img.shields.io/static/v1?label=&message=Notebook&color=blue&style=for-the-badge&logo=googlecolab&link=https://colab.research.google.com/github/ArthurFDLR/whisper-youtube/blob/main/whisper_youtube.ipynb)](https://colab.research.google.com/github/ArthurFDLR/whisper-youtube/blob/main/whisper_youtube.ipynb)\n",
        "[![repository shield](https://img.shields.io/static/v1?label=&message=Repository&color=blue&style=for-the-badge&logo=github&link=https://github.com/openai/whisper)](https://github.com/openai/whisper)\n",
        "[![paper shield](https://img.shields.io/static/v1?label=&message=Paper&color=blue&style=for-the-badge&link=https://cdn.openai.com/papers/whisper.pdf)](https://cdn.openai.com/papers/whisper.pdf)\n",
        "[![model card shield](https://img.shields.io/static/v1?label=&message=Model%20card&color=blue&style=for-the-badge&link=https://github.com/openai/whisper/blob/main/model-card.md)](https://github.com/openai/whisper/blob/main/model-card.md)\n",
        "\n",
        "Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.\n",
        "\n",
        "This Notebook will guide you through the transcription of a Youtube video using Whisper. You'll be able to explore most inference parameters or use the Notebook as-is to store the transcript and video audio in your Google Drive."
      ],
      "metadata": {
        "id": "96kvih9mXkNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Check GPU type** üïµÔ∏è\n",
        "\n",
        "#@markdown The type of GPU you get assigned in your Colab session defined the speed at which the video will be transcribed.\n",
        "#@markdown The higher the number of floating point operations per second (FLOPS), the faster the transcription.\n",
        "#@markdown But even the least powerful GPU available in Colab is able to run any Whisper model.\n",
        "#@markdown Make sure you've selected `GPU` as hardware accelerator for the Notebook (Runtime &rarr; Change runtime type &rarr; Hardware accelerator).\n",
        "\n",
        "#@markdown |  GPU   |  GPU RAM   | FP32 teraFLOPS |     Availability   |\n",
        "#@markdown |:------:|:----------:|:--------------:|:------------------:|\n",
        "#@markdown |  T4    |    16 GB   |       8.1      |         Free       |\n",
        "#@markdown | P100   |    16 GB   |      10.6      |      Colab Pro     |\n",
        "#@markdown | V100   |    16 GB   |      15.7      |  Colab Pro (Rare)  |\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Factory reset your Notebook's runtime if you want to get assigned a new GPU.**\n",
        "\n",
        "!nvidia-smi -L\n",
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "QshUbLqpX7L4",
        "outputId": "104e9424-d1ac-433b-8e7c-ea1ae385e34f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-77397526-5f17-2350-232a-c00beb9b19cd)\n",
            "Mon Jan 22 10:21:16 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P8              13W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IfG0E_WbRFI0",
        "outputId": "8005be4d-0ac0-4fe9-aabe-e1aa49a5d6cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-lrg_whzu\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-lrg_whzu\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.5.2)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.10/dist-packages (2023.12.30)\n",
            "Requirement already satisfied: mutagen in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.47.0)\n",
            "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (3.20.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2023.11.17)\n",
            "Requirement already satisfied: requests<3,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.0.7)\n",
            "Requirement already satisfied: websockets>=12.0 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (12.0)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt-dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt-dlp) (3.6)\n",
            "Collecting transformers==3.2.0\n",
            "  Using cached transformers-3.2.0-py3-none-any.whl (1.0 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from transformers==3.2.0) (1.23.5)\n",
            "Collecting tokenizers==0.8.1.rc2 (from transformers==3.2.0)\n",
            "  Using cached tokenizers-0.8.1rc2.tar.gz (97 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from transformers==3.2.0) (23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==3.2.0) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==3.2.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==3.2.0) (4.66.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==3.2.0) (2023.6.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.10/dist-packages (from transformers==3.2.0) (0.1.99)\n",
            "Collecting sacremoses (from transformers==3.2.0)\n",
            "  Using cached sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==3.2.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==3.2.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==3.2.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==3.2.0) (2023.11.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==3.2.0) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==3.2.0) (1.3.2)\n",
            "Building wheels for collected packages: tokenizers\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m√ó\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build tokenizers\n",
            "\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (4.66.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.1.99)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[sentencepiece]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[sentencepiece]) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2023.11.17)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **Install libraries** üèóÔ∏è\n",
        "#@markdown This cell will take a little while to download several libraries, including Whisper.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! pip install yt-dlp\n",
        "! pip install transformers==3.2.0\n",
        "! pip install transformers[sentencepiece]\n",
        "! pip install sentencepiece\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "import whisper\n",
        "from pathlib import Path\n",
        "import yt_dlp\n",
        "import subprocess\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "from IPython.display import display, Markdown, YouTubeVideo\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1zwGAsr4sIgd",
        "outputId": "2005fc29-13ca-4af8-e07b-5b08c1d9899f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **Optional:** Save data in Google Drive üíæ\n",
        "#@markdown Enter a Google Drive path and run this cell if you want to store the results inside Google Drive.\n",
        "\n",
        "# Uncomment to copy generated images to drive, faster than downloading directly from colab in my experience.\n",
        "from google.colab import drive\n",
        "drive_mount_path = Path(\"/\") / \"content\" / \"drive\"\n",
        "drive.mount(str(drive_mount_path))\n",
        "drive_mount_path /= \"My Drive\"\n",
        "#@markdown ---\n",
        "drive_path = \"stat110_en_zh\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change your Google Drive path.**\n",
        "\n",
        "drive_whisper_path = drive_mount_path / Path(drive_path.lstrip(\"/\"))\n",
        "drive_whisper_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Model selection** üß†\n",
        "\n",
        "#@markdown As of the first public release, there are 4 pre-trained options to play with:\n",
        "\n",
        "#@markdown |  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
        "#@markdown |:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
        "#@markdown |  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n",
        "#@markdown |  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n",
        "#@markdown | small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n",
        "#@markdown | medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n",
        "#@markdown | large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |\n",
        "\n",
        "#@markdown ---\n",
        "Model = 'tiny.en' #@param ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large', \"large-v2\", \"large-v3\"]\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the model.**\n",
        "\n",
        "whisper_model = whisper.load_model(Model)\n",
        "\n",
        "if Model in whisper.available_models():\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is selected.**\"\n",
        "    ))\n",
        "else:\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is no longer available.**<br /> Please select one of the following:<br /> - {'<br /> - '.join(whisper.available_models())}\"\n",
        "    ))"
      ],
      "metadata": {
        "id": "TMhrSq_GZ6kA",
        "outputId": "0edcc6cd-8cab-4be9-e275-5fa0cba61f3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 72.1M/72.1M [00:05<00:00, 13.2MiB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**tiny.en model is selected.**"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Video selection** üì∫\n",
        "\n",
        "#@markdown Enter the URL of the Youtube video you want to transcribe, wether you want to save the audio file in your Google Drive, and run the cell.\n",
        "\n",
        "Type = \"Youtube video or playlist\" #@param ['Youtube video or playlist', 'Google Drive']\n",
        "#@markdown ---\n",
        "#@markdown #### **Youtube video or playlist**\n",
        "URL = \"https://www.youtube.com/watch?v=KStkdUvhEK8\" #@param {type:\"string\"}\n",
        "# store_audio = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown #### **Google Drive video, audio (mp4, wav), or folder containing video and/or audio files**\n",
        "video_path = \"stat110/Lecture 1 Probability and Counting  Statistics 110.mp4\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the video.**\n",
        "\n",
        "video_path_local_list = []\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'm4a/bestaudio/best',\n",
        "        'outtmpl': '%(id)s.%(ext)s',\n",
        "        # ‚ÑπÔ∏è See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments\n",
        "        'postprocessors': [{  # Extract audio using ffmpeg\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav',\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        error_code = ydl.download([URL])\n",
        "        list_video_info = [ydl.extract_info(URL, download=False)]\n",
        "\n",
        "    for video_info in list_video_info:\n",
        "        video_path_local_list.append(Path(f\"{video_info['id']}.wav\"))\n",
        "\n",
        "elif Type == \"Google Drive\":\n",
        "    # video_path_drive = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    video_path = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    if video_path.is_dir():\n",
        "        for video_path_drive in video_path.glob(\"**/*\"):\n",
        "            if video_path_drive.is_file():\n",
        "                display(Markdown(f\"**{str(video_path_drive)} selected for transcription.**\"))\n",
        "            elif video_path_drive.is_dir():\n",
        "                display(Markdown(f\"**Subfolders not supported.**\"))\n",
        "            else:\n",
        "                display(Markdown(f\"**{str(video_path_drive)} does not exist, skipping.**\"))\n",
        "            video_path_local = Path(\".\").resolve() / (video_path_drive.name)\n",
        "            shutil.copy(video_path_drive, video_path_local)\n",
        "            video_path_local_list.append(video_path_local)\n",
        "    elif video_path.is_file():\n",
        "        video_path_local = Path(\".\").resolve() / (video_path.name)\n",
        "        shutil.copy(video_path, video_path_local)\n",
        "        video_path_local_list.append(video_path_local)\n",
        "        display(Markdown(f\"**{str(video_path)} selected for transcription.**\"))\n",
        "    else:\n",
        "        display(Markdown(f\"**{str(video_path)} does not exist.**\"))\n",
        "\n",
        "else:\n",
        "    raise(TypeError(\"Please select supported input type.\"))\n",
        "\n",
        "for video_path_local in video_path_local_list:\n",
        "    if video_path_local.suffix == \".mp4\":\n",
        "        video_path_local = video_path_local.with_suffix(\".wav\")\n",
        "        result  = subprocess.run([\"ffmpeg\", \"-i\", str(video_path_local.with_suffix(\".mp4\")), \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", str(video_path_local)])\n"
      ],
      "metadata": {
        "id": "xYLPZQX9S7tU",
        "outputId": "0137efed-f623-4e50-bc36-25dde6ae8118",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=KStkdUvhEK8\n",
            "[youtube] KStkdUvhEK8: Downloading webpage\n",
            "[youtube] KStkdUvhEK8: Downloading ios player API JSON\n",
            "[youtube] KStkdUvhEK8: Downloading android player API JSON\n",
            "[youtube] KStkdUvhEK8: Downloading m3u8 information\n",
            "[info] KStkdUvhEK8: Downloading 1 format(s): 140\n",
            "[download] Destination: KStkdUvhEK8.m4a\n",
            "[download] 100% of    7.62MiB in 00:00:00 at 38.92MiB/s  \n",
            "[FixupM4a] Correcting container of \"KStkdUvhEK8.m4a\"\n",
            "[ExtractAudio] Destination: KStkdUvhEK8.wav\n",
            "Deleting original file KStkdUvhEK8.m4a (pass -k to keep)\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=KStkdUvhEK8\n",
            "[youtube] KStkdUvhEK8: Downloading webpage\n",
            "[youtube] KStkdUvhEK8: Downloading ios player API JSON\n",
            "[youtube] KStkdUvhEK8: Downloading android player API JSON\n",
            "[youtube] KStkdUvhEK8: Downloading m3u8 information\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-X0qB9JAzMLY",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d61de7c3-bdc8-40d1-e749-27bbe56d738e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### KStkdUvhEK8.wav"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:04.640]  Well, we learned a short time ago, the nominations for this year's BAFTA Awards.\n",
            "[00:04.640 --> 00:09.840]  The film Oppenheimer leads with 13 nominations, so we will have to wait a whole month to\n",
            "[00:09.840 --> 00:14.280]  find out the winners of each award category at the ceremony in February.\n",
            "[00:14.280 --> 00:19.840]  Let's hear again a clip of some of the nominees for the award, including Best Actor and Best Actress.\n",
            "[00:19.840 --> 00:23.560]  And the nominees for lead and actress are\n",
            "[00:23.560 --> 00:30.840]  Fantasia Barino, the Colour Purple, Sandra Hula, Anatomy of a Fall,\n",
            "[00:30.840 --> 00:38.040]  Kerry Mulligan, Maestro, Vivian Opara, Ray Lane,\n",
            "[00:38.040 --> 00:45.560]  Margot Robbie, Barbie, Emma Stone, Poor Things.\n",
            "[00:45.560 --> 00:49.640]  The nominees for leading actor are\n",
            "[00:49.640 --> 00:52.920]  Bradley Cooper, Maestro,\n",
            "[00:52.920 --> 01:00.920]  Coleman Domingo, Rustin, Paul Giamatti, The Holdovers,\n",
            "[01:00.920 --> 01:08.840]  Barry Keogan, Saltburn, Killian Murphy, Oppenheimer,\n",
            "[01:08.840 --> 01:13.480]  Teo Yu, Past Lives.\n",
            "[01:13.480 --> 01:16.920]  Well, with me, is the film critic and producer Jason Solomon's,\n",
            "[01:16.920 --> 01:18.920]  oh, it's really exciting isn't it?\n",
            "[01:18.920 --> 01:19.960]  It is, nice to be here.\n",
            "[01:19.960 --> 01:24.120]  The big theory of the year was always it's Barbie, it's Oppenheimer,\n",
            "[01:24.120 --> 01:28.600]  and they did so well at Golden Globe, they were sort of parallel, but here, totally different.\n",
            "[01:28.600 --> 01:34.920]  Extraordinary, this is the most exciting and diverse and always shocking and yet distinctive\n",
            "[01:34.920 --> 01:38.440]  set of BAFTA nominations for a very long time, which I think is exciting.\n",
            "[01:38.440 --> 01:45.320]  Barbonheimer, yes, the thing that saved cinema, this really odd monster with Barbies' head\n",
            "[01:45.320 --> 01:48.520]  and the Oppenheimer's body, they've been separated here.\n",
            "[01:48.760 --> 01:52.280]  Oppenheimer leads the way 13 nominations across the board,\n",
            "[01:52.280 --> 01:58.280]  BAFTA voters obviously loved its, its important, its heft, its style, its craft,\n",
            "[01:58.280 --> 01:59.640]  and its performances.\n",
            "[01:59.640 --> 02:04.440]  Barbie has not charmed them so much, only five nominations for Barbie,\n",
            "[02:04.440 --> 02:07.320]  and I was expecting sort of double figure nominations for Barbie,\n",
            "[02:07.320 --> 02:11.320]  I have to say Greta Goig, not investor-rector, it's a big surprise.\n",
            "[02:11.320 --> 02:14.840]  Let's have a look at it and just remind ourselves about what the biggest box office\n",
            "[02:14.840 --> 02:16.600]  is to success of the year.\n",
            "[02:16.600 --> 02:17.240]  Yeah.\n",
            "[02:17.240 --> 02:18.440]  Can I come to your house tonight?\n",
            "[02:18.440 --> 02:19.000]  Sure.\n",
            "[02:19.000 --> 02:22.200]  I don't have anything big planned, just a giant blowout party with all the Barbies\n",
            "[02:22.200 --> 02:24.600]  and plant choreography and epis folks on, you should stop by.\n",
            "[02:25.400 --> 02:26.120]  So cool.\n",
            "[02:26.120 --> 02:26.680]  Yeah.\n",
            "[02:26.680 --> 02:27.480]  Okay, bye.\n",
            "[02:45.320 --> 02:48.280]  Well, you can see Barbie in all its glory there,\n",
            "[02:48.280 --> 02:52.040]  mainly shot in the UK as well and it has been nominated for production design,\n",
            "[02:52.040 --> 02:54.040]  as you can see there's Sarah Greenman and the two performers,\n",
            "[02:54.040 --> 02:56.760]  Marga Robbie and Ryan Gosling are both nominated,\n",
            "[02:56.760 --> 03:02.680]  Marga in Best Actress and Ryan brings his energy to supporting actor.\n",
            "[03:02.680 --> 03:06.600]  So it is nominated, it's just not in as many categories as you'd have thought.\n",
            "[03:06.600 --> 03:12.200]  So poor things, it is a British film that has sort of beaten Barbie with 11 nominations,\n",
            "[03:12.200 --> 03:14.360]  that is an outstanding British film.\n",
            "[03:14.440 --> 03:20.520]  And BAFTA is here to show Kate's British film, we have outstanding British film as a category\n",
            "[03:20.520 --> 03:25.480]  and that puts British film on in the spotlight amongst the world and BAFTA voters tend to\n",
            "[03:25.480 --> 03:29.240]  favor some home favourites if you like and anybody else in any British film,\n",
            "[03:29.240 --> 03:31.240]  we have got poor things with that.\n",
            "[03:31.240 --> 03:34.440]  Break great performance from Emma Stone, you might sort of not think of it's a British film,\n",
            "[03:34.440 --> 03:37.480]  but it's based on a Scottish book by Alice De Gray and you're with\n",
            "[03:37.480 --> 03:42.920]  the Atlantic Monster Greek director, does live and work in the UK mainly.\n",
            "[03:42.920 --> 03:47.800]  That is an extraordinary film, it's been sort of snubbed in a few categories such as\n",
            "[03:47.800 --> 03:52.360]  Mark Ruffalo in supporting actor, but it does have Emma Stone just being extraordinary in the lead\n",
            "[03:52.360 --> 03:53.880]  as a Bella.\n",
            "[03:53.880 --> 03:57.400]  She's also just won the Golden Globe, right? So she's on a bit of a role at the moment.\n",
            "[03:57.400 --> 04:01.720]  Yeah, probably the favourite for Best Actress, I would say a lot of people would say that\n",
            "[04:01.720 --> 04:06.920]  Liddy Gladstone in the film, Killers of the Flower Moon is a favourite to beat her at the Oscars,\n",
            "[04:06.920 --> 04:11.240]  she's not snubbed, she's not here, she's not in the best actresses at the BAFTA's which is\n",
            "[04:11.240 --> 04:17.480]  extraordinary. Instead, a British actress Vivian Apara from a film called Rie Lane, which I loved,\n",
            "[04:17.480 --> 04:22.840]  a romantic comedy, Stellan Streets of South London, a debut by Rain and Emmila,\n",
            "[04:22.840 --> 04:28.920]  is a nominated for leading actress and outstanding British film. So that's a real boost for\n",
            "[04:28.920 --> 04:34.520]  sort of first time British film makers such as Molly Manning Walker and her film How to Have Sex\n",
            "[04:34.520 --> 04:39.480]  and Scrap at my Charlotte Regan, some of those small indie British films really pushing\n",
            "[04:39.480 --> 04:41.880]  into the mainstream categories here at the BAFTA.\n",
            "[04:41.880 --> 04:44.920]  I think we've got some clips of some British film, let's have a little look.\n",
            "[04:47.080 --> 04:50.920]  I had them hang up an old school dinner jacket, we dressed for dinner here.\n",
            "[04:50.920 --> 04:52.200]  Just for dinner.\n",
            "[04:52.200 --> 04:54.600]  Yeah, it's like, it was like black time.\n",
            "[04:57.880 --> 05:00.120]  I think I like even more than last year's one.\n",
            "[05:00.280 --> 05:04.840]  You're so, um, so what?\n",
            "[05:06.120 --> 05:07.000]  Real.\n",
            "[05:07.000 --> 05:09.560]  Oh, what did you know? You've escaped the clutches of the colonel.\n",
            "[05:11.480 --> 05:13.160]  Like, with your post-KFC life.\n",
            "[05:13.160 --> 05:14.760]  Oh, I'm the captain.\n",
            "[05:14.760 --> 05:17.160]  Ooh, okay.\n",
            "[05:18.680 --> 05:21.720]  No freeing popcorn chicken, but still, that's like a proper job.\n",
            "[05:21.720 --> 05:23.560]  Yeah, it's not particularly glamorous.\n",
            "[05:23.560 --> 05:24.280]  No.\n",
            "[05:24.280 --> 05:25.320]  But as you kind of love it.\n",
            "[05:25.320 --> 05:27.800]  That's what you've always wanted to do, where we've got yourself some\n",
            "[05:27.800 --> 05:29.560]  14 ambition, barely weighing it up.\n",
            "[05:31.320 --> 05:33.960]  You know, you're very paying for a freshly disarming.\n",
            "[05:33.960 --> 05:34.840]  You asked me a lot of questions.\n",
            "[05:34.840 --> 05:36.120]  I'm interested in people's message.\n",
            "[05:37.640 --> 05:41.800]  So that was Rylane, and we saw salt burn before that as well.\n",
            "[05:41.800 --> 05:44.600]  And as you say, British films, and when we're talking about BAFTA,\n",
            "[05:45.320 --> 05:48.120]  it is a celebration of British film as well, isn't it?\n",
            "[05:48.120 --> 05:52.040]  So would you expect it to be slightly more skewed compared to the globe's compared to the Oscars\n",
            "[05:52.040 --> 05:53.800]  because it has that focus?\n",
            "[05:53.800 --> 05:55.400]  Yes, I would, and it should be.\n",
            "[05:55.400 --> 05:58.040]  You know, it's the British Academy of Film and Television Arts,\n",
            "[05:58.040 --> 06:00.120]  we, that's what they're there for.\n",
            "[06:00.120 --> 06:05.240]  But it also is a global reach, you know, BAFTA in London and the UK,\n",
            "[06:05.240 --> 06:08.360]  they're a global, they have a lot of American film,\n",
            "[06:08.360 --> 06:11.800]  but we also have a very vibrant European and world film culture.\n",
            "[06:11.800 --> 06:14.120]  And that's been reflected a French film,\n",
            "[06:14.120 --> 06:18.360]  Anatomy of a Four, has been nominated seven times an actress Sandra Hula,\n",
            "[06:18.360 --> 06:20.920]  whose German has been nominated both in leading actress\n",
            "[06:20.920 --> 06:23.080]  and in supporting actress for Zone of Interest.\n",
            "[06:23.080 --> 06:26.120]  And that's probably my favourite film of the season,\n",
            "[06:26.120 --> 06:28.680]  but you know, that's got a good chance of best film.\n",
            "[06:28.680 --> 06:32.120]  So there's a very global outlook to these an actor,\n",
            "[06:32.120 --> 06:35.800]  such as T.O.U. who's in a film called Past Lives,\n",
            "[06:35.800 --> 06:37.240]  is nominated in Best Actor.\n",
            "[06:37.240 --> 06:40.120]  That's a big surprise to many, but it's a superb performance.\n",
            "[06:40.120 --> 06:43.080]  So it shows that the reach and the outlook of BAFTA voters\n",
            "[06:43.080 --> 06:45.960]  is sort of east and west looking all over the globe.\n",
            "[06:45.960 --> 06:47.000]  It's quite exciting.\n",
            "[06:47.000 --> 06:50.600]  Diversity is often an issue at these water areas, isn't it?\n",
            "[06:50.600 --> 06:52.920]  And certainly it has been for BAFTA in the past,\n",
            "[06:52.920 --> 06:55.800]  how reflective, how diverse the nominees this year.\n",
            "[06:55.800 --> 06:59.000]  Yeah, I mean, in Best Film, you have a French film,\n",
            "[06:59.000 --> 07:02.680]  you have a Greek director, you have Killers of the Flower Moon,\n",
            "[07:02.680 --> 07:04.760]  which is about indigenous communities in America.\n",
            "[07:04.760 --> 07:06.600]  So there is a slight diversity,\n",
            "[07:06.600 --> 07:11.000]  and I'm not saying there's a huge blanket of diversity opening.\n",
            "[07:11.000 --> 07:13.880]  But in outstanding British, we do have female filmmakers,\n",
            "[07:13.880 --> 07:16.040]  we have a black filmmaker in rain,\n",
            "[07:16.040 --> 07:18.200]  Alimina, we have a foreign language film,\n",
            "[07:18.200 --> 07:19.160]  the Zone of Interest.\n",
            "[07:19.160 --> 07:21.400]  So that's a German film, but it is British,\n",
            "[07:22.040 --> 07:22.920]  German language.\n",
            "[07:22.920 --> 07:28.120]  So, and we have a film, LGBTQ plus communities representing\n",
            "[07:28.120 --> 07:29.160]  in all of us straighter.\n",
            "[07:29.160 --> 07:29.960]  So it is there.\n",
            "[07:29.960 --> 07:32.520]  There is a sort of this vibrant mix in British film,\n",
            "[07:32.520 --> 07:34.120]  and I think that has been reflected\n",
            "[07:34.120 --> 07:37.000]  and to enjoy Randolph in supporting actors.\n",
            "[07:38.440 --> 07:41.160]  It's not a celebration of diversity as such,\n",
            "[07:41.160 --> 07:42.680]  but that is, it is there.\n",
            "[07:43.640 --> 07:45.880]  And you know, I don't want to sort of do the BAFTA's\n",
            "[07:45.880 --> 07:47.800]  to white, that's not fair on the BAFTA's.\n",
            "[07:47.800 --> 07:49.640]  So it can only vote for what's in front.\n",
            "[07:49.640 --> 07:52.920]  And the went, when diverse excellence has been there,\n",
            "[07:52.920 --> 07:54.280]  it has been championed.\n",
            "[07:54.280 --> 07:56.760]  Jason, take it, the BAFTA ceremony is when?\n",
            "[07:56.760 --> 07:59.080]  18th of February on BBC One.\n",
            "[07:59.080 --> 08:01.880]  And it's hosted by David Tennant, I know.\n",
            "[08:01.880 --> 08:02.840]  Which will be the doctor.\n",
            "[08:02.840 --> 08:06.440]  The doctor, which will be great, is absolute joy speaking to you.\n",
            "[08:06.440 --> 08:08.840]  You've wetted my appetite, because it's so fascinating.\n",
            "[08:08.840 --> 08:10.280]  You've got lots of catch up on me in time.\n",
            "[08:10.280 --> 08:12.040]  And he's got lots of films to go and watch.\n",
            "[08:12.040 --> 08:13.800]  Yeah, go on. Thank you. Thank you, Jason.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 146/146 [02:16<00:00,  1.07it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Transcript file created: /content/drive/My Drive/stat110_en_zh/KStkdUvhEK8.srt**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Transcript file created: /content/drive/My Drive/stat110_en_zh/KStkdUvhEK8_zh.srt**"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "import copy\n",
        "#@markdown # **Run the model** üöÄ\n",
        "\n",
        "#@markdown Run this cell to execute the transcription of the video. This can take a while and very based on the length of the video and the number of parameters of the model selected above.\n",
        "\n",
        "#@markdown ## **Parameters** ‚öôÔ∏è\n",
        "\n",
        "#@markdown ### **Behavior control**\n",
        "#@markdown ---\n",
        "language = \"English\" #@param ['Auto detection', 'Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Assamese', 'Azerbaijani', 'Bashkir', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Breton', 'Bulgarian', 'Burmese', 'Castilian', 'Catalan', 'Chinese', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Faroese', 'Finnish', 'Flemish', 'French', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hungarian', 'Icelandic', 'Indonesian', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Lao', 'Latin', 'Latvian', 'Letzeburgesch', 'Lingala', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Moldavian', 'Moldovan', 'Mongolian', 'Myanmar', 'Nepali', 'Norwegian', 'Nynorsk', 'Occitan', 'Panjabi', 'Pashto', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Pushto', 'Romanian', 'Russian', 'Sanskrit', 'Serbian', 'Shona', 'Sindhi', 'Sinhala', 'Sinhalese', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Thai', 'Tibetan', 'Turkish', 'Turkmen', 'Ukrainian', 'Urdu', 'Uzbek', 'Valencian', 'Vietnamese', 'Welsh', 'Yiddish', 'Yoruba']\n",
        "#@markdown > Language spoken in the audio, use `Auto detection` to let Whisper detect the language.\n",
        "#@markdown ---\n",
        "en_zh = True #@param {type:\"boolean\"}\n",
        "#@markdown > Translate English into Chinese.\n",
        "#@markdown ---\n",
        "verbose = 'Live transcription' #@param ['Live transcription', 'Progress bar', 'None']\n",
        "#@markdown > Whether to print out the progress and debug messages.\n",
        "#@markdown ---\n",
        "output_format = 'srt' #@param ['txt', 'vtt', 'srt', 'tsv', 'json', 'all']\n",
        "#@markdown > Type of file to generate to record the transcription.\n",
        "#@markdown ---\n",
        "task = 'transcribe' #@param ['transcribe', 'translate']\n",
        "#@markdown > Whether to perform X->X speech recognition (`transcribe`) or X->English translation (`translate`).\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown <br/>\n",
        "\n",
        "#@markdown ### **Optional: Fine tunning**\n",
        "#@markdown ---\n",
        "temperature = 0.15 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "#@markdown > Temperature to use for sampling.\n",
        "#@markdown ---\n",
        "temperature_increment_on_fallback = 0.2 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "#@markdown > Temperature to increase when falling back when the decoding fails to meet either of the thresholds below.\n",
        "#@markdown ---\n",
        "best_of = 5 #@param {type:\"integer\"}\n",
        "#@markdown > Number of candidates when sampling with non-zero temperature.\n",
        "#@markdown ---\n",
        "beam_size = 8 #@param {type:\"integer\"}\n",
        "#@markdown > Number of beams in beam search, only applicable when temperature is zero.\n",
        "#@markdown ---\n",
        "patience = 1.0 #@param {type:\"number\"}\n",
        "#@markdown > Optional patience value to use in beam decoding, as in [*Beam Decoding with Controlled Patience*](https://arxiv.org/abs/2204.05424), the default (1.0) is equivalent to conventional beam search.\n",
        "#@markdown ---\n",
        "length_penalty = -0.05 #@param {type:\"slider\", min:-0.05, max:1, step:0.05}\n",
        "#@markdown > Optional token length penalty coefficient (alpha) as in [*Google's Neural Machine Translation System*](https://arxiv.org/abs/1609.08144), set to negative value to uses simple length normalization.\n",
        "#@markdown ---\n",
        "suppress_tokens = \"-1\" #@param {type:\"string\"}\n",
        "#@markdown > Comma-separated list of token ids to suppress during sampling; '-1' will suppress most special characters except common punctuations.\n",
        "#@markdown ---\n",
        "initial_prompt = \"\" #@param {type:\"string\"}\n",
        "#@markdown > Optional text to provide as a prompt for the first window.\n",
        "#@markdown ---\n",
        "condition_on_previous_text = True #@param {type:\"boolean\"}\n",
        "#@markdown > if True, provide the previous output of the model as a prompt for the next window; disabling may make the text inconsistent across windows, but the model becomes less prone to getting stuck in a failure loop.\n",
        "#@markdown ---\n",
        "fp16 = True #@param {type:\"boolean\"}\n",
        "#@markdown > whether to perform inference in fp16.\n",
        "#@markdown ---\n",
        "compression_ratio_threshold = 2.4 #@param {type:\"number\"}\n",
        "#@markdown > If the gzip compression ratio is higher than this value, treat the decoding as failed.\n",
        "#@markdown ---\n",
        "logprob_threshold = -1.0 #@param {type:\"number\"}\n",
        "#@markdown > If the average log probability is lower than this value, treat the decoding as failed.\n",
        "#@markdown ---\n",
        "no_speech_threshold = 0.6 #@param {type:\"slider\", min:-0.0, max:1, step:0.05}\n",
        "#@markdown > If the probability of the <|nospeech|> token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence.\n",
        "#@markdown ---\n",
        "\n",
        "verbose_lut = {\n",
        "    'Live transcription': True,\n",
        "    'Progress bar': False,\n",
        "    'None': None\n",
        "}\n",
        "\n",
        "# translate\n",
        "if language == \"English\" and en_zh:\n",
        "  translate_model_name = \"Helsinki-NLP/opus-mt-en-zh\"\n",
        "  translate_tokenizer = MarianTokenizer.from_pretrained(translate_model_name)\n",
        "  translate_model = MarianMTModel.from_pretrained(translate_model_name)\n",
        "\n",
        "args = dict(\n",
        "    language = (None if language == \"Auto detection\" else language),\n",
        "    verbose = verbose_lut[verbose],\n",
        "    task = task,\n",
        "    temperature = temperature,\n",
        "    temperature_increment_on_fallback = temperature_increment_on_fallback,\n",
        "    best_of = best_of,\n",
        "    beam_size = beam_size,\n",
        "    patience=patience,\n",
        "    length_penalty=(length_penalty if length_penalty>=0.0 else None),\n",
        "    suppress_tokens=suppress_tokens,\n",
        "    initial_prompt=(None if not initial_prompt else initial_prompt),\n",
        "    condition_on_previous_text=condition_on_previous_text,\n",
        "    fp16=fp16,\n",
        "    compression_ratio_threshold=compression_ratio_threshold,\n",
        "    logprob_threshold=logprob_threshold,\n",
        "    no_speech_threshold=no_speech_threshold\n",
        ")\n",
        "\n",
        "temperature = args.pop(\"temperature\")\n",
        "temperature_increment_on_fallback = args.pop(\"temperature_increment_on_fallback\")\n",
        "if temperature_increment_on_fallback is not None:\n",
        "    temperature = tuple(np.arange(temperature, 1.0 + 1e-6, temperature_increment_on_fallback))\n",
        "else:\n",
        "    temperature = [temperature]\n",
        "\n",
        "if Model.endswith(\".en\") and args[\"language\"] not in {\"en\", \"English\"}:\n",
        "    warnings.warn(f\"{Model} is an English-only model but receipted '{args['language']}'; using English instead.\")\n",
        "    args[\"language\"] = \"en\"\n",
        "\n",
        "for video_path_local in video_path_local_list:\n",
        "    display(Markdown(f\"### {video_path_local}\"))\n",
        "\n",
        "    video_transcription = whisper.transcribe(\n",
        "        whisper_model,\n",
        "        str(video_path_local),\n",
        "        temperature=temperature,\n",
        "        **args,\n",
        "    )\n",
        "    # Translation\n",
        "    if language == \"English\" and en_zh:\n",
        "      temp_lst = []\n",
        "      translation = []\n",
        "      for item in tqdm(video_transcription[\"segments\"]):\n",
        "        temp_lst.append(item)\n",
        "        if temp_lst[-1][\"text\"].endswith((\".\", \"?\", \"!\")):\n",
        "          src_text = \"\".join([x[\"text\"] for x in temp_lst])\n",
        "          input_ids = translate_tokenizer(src_text, return_tensors=\"pt\").input_ids\n",
        "          outputs = translate_model.generate(input_ids)\n",
        "          outputs = translate_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "          num_chunks = len(temp_lst)\n",
        "          total_time = temp_lst[-1][\"end\"] - temp_lst[0][\"start\"]\n",
        "          chunk_size = [(x[\"end\"] - x[\"start\"]) / total_time for x in temp_lst]\n",
        "\n",
        "          left = 0\n",
        "          for i in range(num_chunks):\n",
        "            right = left + chunk_size[i]\n",
        "            left_index = int(left * len(outputs))\n",
        "            right_index = int(right * len(outputs))\n",
        "            temp_lst[i][\"text\"] = outputs[left_index: right_index]\n",
        "            left = right\n",
        "\n",
        "          for temp in temp_lst:\n",
        "            translation.append(temp)\n",
        "\n",
        "          temp_lst = []\n",
        "      video_translation = copy.deepcopy(video_transcription)\n",
        "      video_translation[\"segments\"] = translation\n",
        "      whisper.utils.get_writer(\n",
        "          output_format=output_format,\n",
        "          output_dir=video_path_local.parent\n",
        "      )(\n",
        "          video_translation,\n",
        "          str(video_path_local.stem) + \"_zh\",\n",
        "          options=dict(\n",
        "              highlight_words=False,\n",
        "              max_line_count=None,\n",
        "              max_line_width=None,\n",
        "          )\n",
        "      )\n",
        "\n",
        "    # Save output\n",
        "    whisper.utils.get_writer(\n",
        "        output_format=output_format,\n",
        "        output_dir=video_path_local.parent\n",
        "    )(\n",
        "        video_transcription,\n",
        "        str(video_path_local.stem),\n",
        "        options=dict(\n",
        "            highlight_words=False,\n",
        "            max_line_count=None,\n",
        "            max_line_width=None,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    def exportTranscriptFile(ext: str):\n",
        "        local_path = video_path_local.parent / video_path_local.with_suffix(ext).name\n",
        "        export_path = drive_whisper_path / video_path_local.with_suffix(ext).name\n",
        "        shutil.copy(\n",
        "            local_path,\n",
        "            export_path\n",
        "        )\n",
        "        display(Markdown(f\"**Transcript file created: {export_path}**\"))\n",
        "\n",
        "    def exportTranslateFile(ext: str):\n",
        "        local_path = video_path_local.parent / (video_path_local.stem + \"_zh\" + ext)\n",
        "        export_path = drive_whisper_path / (video_path_local.stem + \"_zh\" + ext)\n",
        "        shutil.copy(\n",
        "            local_path,\n",
        "            export_path\n",
        "        )\n",
        "        display(Markdown(f\"**Transcript file created: {export_path}**\"))\n",
        "\n",
        "    if output_format==\"all\":\n",
        "        for ext in ('.txt', '.vtt', '.srt', '.tsv', '.json'):\n",
        "            exportTranscriptFile(ext)\n",
        "            if language == \"English\" and en_zh:\n",
        "              exportTranslateFile(ext)\n",
        "    else:\n",
        "        exportTranscriptFile(\".\" + output_format)\n",
        "        if language == \"English\" and en_zh:\n",
        "          exportTranslateFile(\".\" + output_format)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}